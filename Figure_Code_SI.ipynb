{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from collections import Counter\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import poisson\n",
    "from scipy.special import zeta\n",
    "import seaborn as sb\n",
    "import matplotlib.cm as cm\n",
    "from scipy.stats import binom\n",
    "import copy\n",
    "from Bio import Phylo\n",
    "from ete3 import Tree, TreeStyle, NodeStyle\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "from data_analysis_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "tonsil_vdjs_path = 'Data/tonsil_vdjs.tsv'\n",
    "metadata_path = \"Data/tonsil_LR_spatialbc_metadata.csv\"\n",
    "UMI_collapsed_path = \"Data/UMI_collapsed_on_tissue_read_list.csv\"\n",
    "clone_list_path = \"Data/tonsil_all_ontissue_clone_list.csv\"\n",
    "\n",
    "# Read in data\n",
    "df_IGH_IF, df_IGH_EF_PBdom, df_combined, df_TRB, metadata_df, df_IGH_EF, df_IGH = data_readin(tonsil_vdjs_path, metadata_path, UMI_collapsed_path, clone_list_path)\n",
    "\n",
    "# Write sequences of multi-clone lineages to FASTA files for tree construction\n",
    "# Note that FastTree must be run separately on these files to generate the trees\n",
    "lineage_ids, lineage_lens, N_trees, N_lineages_tot = prepare_sequences_for_trees(df_IGH, df_IGH_IF,df_combined, write_files = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE S1: Clone statistics across barcodes\n",
    "\n",
    "# Clone statistics\n",
    "n_clones_IF = df_IGH_IF['vdj_sequence'].nunique()\n",
    "vdj_counts_IF = df_IGH_IF['vdj_sequence'].value_counts()\n",
    "n_clones_repeated_IF = (vdj_counts_IF > 1).sum()\n",
    "vdj_barcode_counts_IF = df_IGH_IF.groupby(['vdj_sequence', 'st_barcode']).size()\n",
    "n_clones_repeated_stbc_IF = (vdj_barcode_counts_IF > 1).groupby(level=0).any().sum()\n",
    "values_IF = [n_clones_IF - n_clones_repeated_IF, n_clones_repeated_IF - n_clones_repeated_stbc_IF, n_clones_repeated_stbc_IF]\n",
    "labels = ['Unique clones', 'Repeated (diff. spatial BCs only)', 'Repeated clones (with same spatial BC)']\n",
    "colors = ['#66c2a5', '#3288bd', '#1b2838']  # teal, blue, dark navy\n",
    "\n",
    "# For each vdj_sequence with vdj_barcode_counts_IF > 1, count unique st_barcodes it is associated with\n",
    "vdj_with_repeats = vdj_barcode_counts_IF[vdj_barcode_counts_IF > 1].index.get_level_values(0).unique()\n",
    "unique_st_barcodes_per_vdj = [\n",
    "    df_IGH_IF[df_IGH_IF['vdj_sequence'] == vdj]['st_barcode'].nunique()\n",
    "    for vdj in vdj_with_repeats\n",
    "]\n",
    "print((\"Fraction of repeatedly sampled clones sampled across multiple barcodes = \" +  str(np.sum(np.array(unique_st_barcodes_per_vdj) > 1)/len(unique_st_barcodes_per_vdj))))\n",
    "\n",
    "# Count unique vdj_sequences that appear exactly twice, both with the same st_barcode\n",
    "vdj_counts_exact2 = vdj_barcode_counts_IF.groupby(level=0).sum()\n",
    "vdj_twice = vdj_counts_exact2[vdj_counts_exact2 == 2].index\n",
    "\n",
    "# For these, check if both counts are for the same st_barcode\n",
    "vdj_twice_same_stbc = [\n",
    "    vdj for vdj in vdj_twice\n",
    "    if df_IGH_IF[df_IGH_IF['vdj_sequence'] == vdj]['st_barcode'].nunique() == 1\n",
    "]\n",
    "fraction_twice_same_stbc = len(vdj_twice_same_stbc) / df_IGH_IF['vdj_sequence'].nunique()\n",
    "print(\"Fraction of unique vdj_sequences appearing exactly twice, both with the same st_barcode =\", fraction_twice_same_stbc)\n",
    "\n",
    "n_clones_EF = df_IGH_EF['vdj_sequence'].nunique()\n",
    "vdj_counts_EF = df_IGH_EF['vdj_sequence'].value_counts()\n",
    "n_clones_repeated_EF = (vdj_counts_EF > 1).sum()\n",
    "vdj_barcode_counts_EF = df_IGH_EF.groupby(['vdj_sequence', 'st_barcode']).size()\n",
    "n_clones_repeated_stbc_EF= (vdj_barcode_counts_EF > 1).groupby(level=0).any().sum()\n",
    "values_EF = [n_clones_EF - n_clones_repeated_EF, n_clones_repeated_EF - n_clones_repeated_stbc_EF, n_clones_repeated_stbc_EF]\n",
    "\n",
    "n_clones_EF_PBdom = df_IGH_EF_PBdom['vdj_sequence'].nunique()\n",
    "vdj_counts_EF_PBdom = df_IGH_EF_PBdom['vdj_sequence'].value_counts()\n",
    "n_clones_repeated_EF_PBdom = (vdj_counts_EF_PBdom > 1).sum()\n",
    "vdj_barcode_counts_EF_PBdom = df_IGH_EF_PBdom.groupby(['vdj_sequence', 'st_barcode']).size()\n",
    "n_clones_repeated_stbc_EF_PBdom = (vdj_barcode_counts_EF_PBdom > 1).groupby(level=0).any().sum()\n",
    "values_EF_PBdom = [\n",
    "    n_clones_EF_PBdom - n_clones_repeated_EF_PBdom,\n",
    "    n_clones_repeated_EF_PBdom - n_clones_repeated_stbc_EF_PBdom,\n",
    "    n_clones_repeated_stbc_EF_PBdom\n",
    "]\n",
    "\n",
    "x_if, surv_if = survival_func(vdj_barcode_counts_IF.values)\n",
    "x_ef, surv_ef = survival_func(vdj_barcode_counts_EF.values)\n",
    "x_ef_pbdom, surv_ef_pbdom = survival_func(vdj_barcode_counts_EF_PBdom.values)\n",
    "\n",
    "# Survival function for number of unique vdj_sequences per st_barcode in IF\n",
    "vdj_per_stbc_IF = df_IGH_IF.groupby('st_barcode')['vdj_sequence'].nunique()\n",
    "x_vdj_stbc, surv_vdj_stbc = survival_func(vdj_per_stbc_IF.values)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(9, 3))\n",
    "\n",
    "# Bar chart (left subplot)\n",
    "axs[0].bar(['IF'], [sum(values_IF)], color='white', edgecolor='black')\n",
    "bottom = 0\n",
    "for v, l, c in zip(values_IF, labels, colors):\n",
    "    axs[0].bar(['IF'], [v], bottom=bottom, color=c)\n",
    "    bottom += v\n",
    "\n",
    "axs[0].bar(['EF (PBs)'], [sum(values_EF_PBdom)], color='white', edgecolor='black')\n",
    "bottom = 0\n",
    "for v, l, c in zip(values_EF_PBdom, labels, colors):\n",
    "    axs[0].bar(['EF (PBs)'], [v], bottom=bottom, color=c)\n",
    "    bottom += v\n",
    "\n",
    "axs[0].bar(['EF (all)'], [sum(values_EF)], color='white', edgecolor='black')\n",
    "bottom = 0\n",
    "for v, l, c in zip(values_EF, labels, colors):\n",
    "    axs[0].bar(['EF (all)'], [v], bottom=bottom, color=c)\n",
    "    bottom += v\n",
    "\n",
    "axs[0].set_ylabel('Number of clones')\n",
    "axs[0].set_xticks(['IF', 'EF (PBs)', 'EF (all)'])\n",
    "\n",
    "# Survival function (middle subplot)\n",
    "axs[1].plot(x_if, surv_if, label='IF', color='black', linewidth=3)\n",
    "axs[1].plot(x_ef, surv_ef, label='EF (all)', color=[0.6,0,0], linewidth=3)\n",
    "axs[1].plot(x_ef_pbdom, surv_ef_pbdom, label='EF (PBs)', color=[1,0.3,0.3], linestyle='--', linewidth=3)\n",
    "axs[1].set_yscale('log')\n",
    "#axs[1].set_xscale('log')\n",
    "axs[1].set_xlabel('# UMIs per clone-location pair, n')\n",
    "axs[1].set_ylabel('Frac. pairs with >= n UMIs')\n",
    "axs[1].set_xlim(left=1)\n",
    "axs[1].set_xticks([1, 10, 20, 30])\n",
    "axs[1].legend()\n",
    "\n",
    "# Survival function for unique vdj_sequences per st_barcode (right subplot)\n",
    "axs[2].plot(x_vdj_stbc, surv_vdj_stbc, color='black', linewidth=3)\n",
    "axs[2].set_yscale('log')\n",
    "axs[2].set_xlim(left=1)\n",
    "axs[2].set_xticks([1,10,20])\n",
    "axs[2].set_xlabel('# unique clones per spatial BC')\n",
    "axs[2].set_ylabel('Frac. spatial BCs with >= n clones')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(r'Figures\\Supplementary\\SI_Clone_Barcode_Statistics_Subplots.pdf', format='pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE S2: Lineage calling threshold\n",
    "\n",
    "# CDR3 clustering\n",
    "\n",
    "dist_list_CDR3 = []\n",
    "thresholds = np.array([0.1, 0.12, 0.14, 0.16, 0.18, 0.2, 0.22, 0.24, 0.26, 0.28, 0.3])\n",
    "\n",
    "import sys, os, time\n",
    "import scipy.spatial.distance as ssd\n",
    "\n",
    "sys.path.append(r\"snakemake_workflow\\scripts\")\n",
    "sys.path.append(r\"snakemake_workflow\\scripts\\cython_packages\")\n",
    "\n",
    "from pacbio_vdj_utils import *\n",
    "from pacbio_vdj_utils.cluster_vdj import *\n",
    "\n",
    "for j in range(len(thresholds)):\n",
    "    airr_path = \"Data/Clustering_Analysis/igblast_filtered_annotated_preprocessed.tsv\"\n",
    "    mat_path = \"Data//Clustering_Analysis/cdr3_dist_mats/\"\n",
    "    OUTDIR = \"Data/Clustering_Analysis/cdr3_clusters/\"\n",
    "    V_SSTART_MAX = 0\n",
    "    C_SSTART_MAX = 0\n",
    "    FRACTIONAL_CUTOFF = thresholds[j]\n",
    "\n",
    "    SAMPLENAME= \"tonsil_vdjs\"\n",
    "\n",
    "    #    large_groups = expand(\n",
    "    #        \"{base}/lineage_clustering/cdr3/{group}_cdr3.npy\",\n",
    "    #        base=wildcards.base,\n",
    "    #        group=glob_wildcards(\n",
    "    #            os.path.join(checkpoint_output, \"{group}_cdr3.fasta\")\n",
    "    #        ).group,\n",
    "    #    )\n",
    "    #    return large_groups\n",
    "\n",
    "    df = pd.read_table(airr_path, usecols=['sequence',\n",
    "                                'v_family',\n",
    "                                'v_sequence_alignment',\n",
    "                                'j_sequence_alignment',\n",
    "                                'v_sequence_start',\n",
    "                                'v_germline_start',\n",
    "                                'v_germline_alignment',\n",
    "                                'j_germline_alignment',\n",
    "                                'cdr3_start',\n",
    "                                'cdr3_end',\n",
    "                                'cdr3',\n",
    "                                'j_sequence_end','locus'])\n",
    "\n",
    "    df['cdr3_length'] = df['cdr3'].str.len()\n",
    "\n",
    "    sys.stderr.write(f\"Starting with {df.shape[0]} reads...\\n\")\n",
    "\n",
    "    df = df[df.v_germline_start <= V_SSTART_MAX + 1]\n",
    "    try:\n",
    "        df = df[df['c_sstart'] <= C_SSTART_MAX + 1]\n",
    "    except KeyError:\n",
    "        pass\n",
    "    sys.stderr.write(f\"Keeping {df.shape[0]} reads that contain entire VDJ region...\\n\")\n",
    "\n",
    "    #df = df[df['v_family'].str.startswith(\"IGH\")]\n",
    "    #sys.stderr.write(\"Subsetting to {} reads that map to heavy chain...\\n\".format(df.shape[0]))\n",
    "\n",
    "    df['vdj_sequence'] = df.apply(lambda x: x.sequence[int(x.v_sequence_start)-1:\n",
    "                                        int(x.j_sequence_end)], axis = 1)\n",
    "\n",
    "    df['v_templated_len'] = df['cdr3_start'] - df['v_sequence_start']\n",
    "    df['j_templated_len'] = df['j_sequence_end'] - df['cdr3_end']\n",
    "\n",
    "    # drop reads with gap in templated alignment\n",
    "    df['sum_gap_len'] = df.v_sequence_alignment.map(lambda x: x.count(\"-\"))\n",
    "    df['sum_gap_len'] = df['sum_gap_len'] + df.j_sequence_alignment.map(lambda x: x.count(\"-\"))\n",
    "    df = df[df['sum_gap_len'] < 1]\n",
    "\n",
    "    sys.stderr.write(f\"Keeping {df.shape[0]} reads with no deletions in templated sequences...\\n\")\n",
    "\n",
    "    df['sum_insertion_len'] = df.v_germline_alignment.map(lambda x: x.count(\"-\"))\n",
    "    df['sum_insertion_len'] = df['sum_insertion_len'] + df.j_germline_alignment.map(lambda x: x.count(\"-\"))\n",
    "    df = df[df['sum_insertion_len'] < 1]\n",
    "\n",
    "    sys.stderr.write(f\"Keeping {df.shape[0]} reads with no insertions in templated sequences...\\n\")\n",
    "\n",
    "    unique_vdjs = df[['v_family',\n",
    "                    'vdj_sequence',\n",
    "                    'v_templated_len',\n",
    "                    'j_templated_len',\n",
    "                    'cdr3',\n",
    "                    'cdr3_length','locus']].drop_duplicates(ignore_index=True)\n",
    "\n",
    "    unique_vdjs['cdr3_group'] = unique_vdjs['v_family'] + \"_\" + unique_vdjs.cdr3_length.astype(str)\n",
    "\n",
    "    cdr3_group_sizes = unique_vdjs.cdr3_group.value_counts()\n",
    "    unique_vdjs['cdr3_group_size'] = unique_vdjs.cdr3_group.map(cdr3_group_sizes)\n",
    "\n",
    "    sys.stderr.write(\"Verifying that all distance matrices are available...\\n\")\n",
    "    for cdr3_group in unique_vdjs.cdr3_group.unique():\n",
    "        vfam, cdr3_len = cdr3_group.split(\"_\")[0], cdr3_group.split(\"_\")[1]\n",
    "        binary_matrix_filename = f'{mat_path}/{SAMPLENAME}_{vfam}_{cdr3_len}_cdr3.npy'\n",
    "        if os.path.exists(binary_matrix_filename):\n",
    "            pass\n",
    "        else:\n",
    "            sys.stderr.write(f\"Cannot find the following file {binary_matrix_filename}. Aborting...\\n\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    sys.stderr.write(f\"Clustering {unique_vdjs.shape[0]} unique variable sequences...\\n\")\n",
    "\n",
    "\n",
    "    TOTAL_CLUSTERS = 0\n",
    "    unique_vdjs['cluster_id'] = -1\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for cdr3_group in unique_vdjs.cdr3_group.unique():\n",
    "        IGH_flag = not unique_vdjs[(unique_vdjs['cdr3_group'] == cdr3_group) & (unique_vdjs['locus'] == 'IGH')].empty\n",
    "\n",
    "        vfam, cdr3_len = cdr3_group.split(\"_\")[0], int(cdr3_group.split(\"_\")[1])\n",
    "\n",
    "        subset = unique_vdjs[unique_vdjs['cdr3_group'] == cdr3_group]\n",
    "\n",
    "        cdr3_seqs = subset.cdr3.values\n",
    "        subset_idx = subset.index\n",
    "\n",
    "        #sys.stderr.write(f\"Processing VDJ sequence subset: v_family={vfam}, cdr3_length={cdr3_len}, n={subset.shape[0]}\\n\")\n",
    "\n",
    "        binary_matrix_filename = f'{mat_path}/{SAMPLENAME}_{vfam}_{cdr3_len}_cdr3.npy'\n",
    "\n",
    "        Ds = np.load(binary_matrix_filename,allow_pickle = False)\n",
    "        n=Ds.shape[0]\n",
    "        diag_indices = np.diag_indices(n)\n",
    "        Ds[diag_indices] = np.uint8(255)\n",
    "        closest_d = np.min(Ds, axis=1)\n",
    "\n",
    "        Ds[diag_indices] = np.uint8(0)\n",
    "\n",
    "        if n > 1:\n",
    "            upper_triangular_indices = np.triu_indices(n, 1)\n",
    "            if thresholds[j] == 0.2 and IGH_flag: dist_list_CDR3.extend((Ds[upper_triangular_indices]/cdr3_len).tolist())\n",
    "\n",
    "            #cluster CDR3s\n",
    "            cutoff = np.uint8(FRACTIONAL_CUTOFF*cdr3_len)\n",
    "            #Ds = ssd.squareform(Ds)\n",
    "            \n",
    "            condensed_distance_matrix = Ds[upper_triangular_indices]\n",
    "\n",
    "            new_cluster_ids = get_cluster_ids(condensed_distance_matrix,\n",
    "                                            cutoff=cutoff,\n",
    "                                            method='single')\n",
    "        else:\n",
    "            new_cluster_ids = np.zeros(1)\n",
    "\n",
    "        unique_vdjs.loc[subset_idx, 'cluster_id'] = TOTAL_CLUSTERS + new_cluster_ids\n",
    "        TOTAL_CLUSTERS += max(new_cluster_ids) + 1\n",
    "\n",
    "    sys.stderr.write(f\"Clustering CDR3s took {round(time.time() - start)} seconds\\n\")\n",
    "\n",
    "    unique_vdjs['templated_v'] = unique_vdjs.apply(lambda x: x.vdj_sequence[0:int(x.v_templated_len)], axis=1)\n",
    "    unique_vdjs['templated_j'] = unique_vdjs.apply(lambda x: x.vdj_sequence[-int(x.j_templated_len):], axis=1)\n",
    "\n",
    "    unique_vdjs.to_csv(f\"{OUTDIR}/{SAMPLENAME}_unique_vdjs_cdr3_clusters_threshold_{FRACTIONAL_CUTOFF}.tsv\", sep= '\\t')\n",
    "\n",
    "    sys.stderr.write(\"Preparing to cluster templated sequences within cdr3 clusters...\\n\")\n",
    "\n",
    "    cluster_sizes = unique_vdjs.cluster_id.value_counts()\n",
    "    unique_vdjs['cluster_size'] = unique_vdjs.cluster_id.map(cluster_sizes)\n",
    "\n",
    "    groups = unique_vdjs['cluster_id'].unique()\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    sys.stderr.write(\n",
    "        f\"Calculating distance matrices for {len(unique_vdjs.cluster_id.unique())} unique clusters...\\n\")\n",
    "\n",
    "    for cluster_id in groups:\n",
    "        subset = unique_vdjs[unique_vdjs['cluster_id'] == cluster_id]\n",
    "        \n",
    "        for seq_element in ['templated_v', 'templated_j']:\n",
    "            BINARY_MATRIX_FILENAME = f'{OUTDIR}/{SAMPLENAME}_{cluster_id}_{seq_element}_threshold_{FRACTIONAL_CUTOFF}.npy'\n",
    "\n",
    "            templated_seqs = subset[seq_element].values\n",
    "            n = len(templated_seqs)\n",
    "            subset_idx = subset.index\n",
    "\n",
    "            sys.stderr.write(\n",
    "                f\"Processing VDJ sequence subset: cluster_id={cluster_id}, n={n}\\n\")\n",
    "\n",
    "            sys.stderr.write(\"\\t computing distance matrix locally...\\n\")\n",
    "\n",
    "            D = np.zeros((n,n),np.uint8)\n",
    "\n",
    "            for i in range(n):\n",
    "                for j in range(i):\n",
    "                    d = distance(templated_seqs[i], templated_seqs[j])\n",
    "                    d = np.uint8(min(d, 255))\n",
    "                    D[i,j] = d\n",
    "                    D[j,i] = d\n",
    "\n",
    "            np.save(BINARY_MATRIX_FILENAME, D, allow_pickle=False)\n",
    "\n",
    "        sys.stderr.write(f\"\\t\\t this took {time.time() - start} seconds\\n\")\n",
    "\n",
    "\n",
    "    sys.stderr.write(f'Done! Execution took {(time.time() - start)} seconds\\n')\n",
    "\n",
    "dist_list_CDR3 = np.array(dist_list_CDR3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VJ filtering for final lineage IDs\n",
    "\n",
    "import scipy.spatial.distance as ssd\n",
    "\n",
    "from pacbio_vdj_utils.cluster_vdj import *\n",
    "dist_list_VJ = []\n",
    "\n",
    "\n",
    "for j in range(len(thresholds)):\n",
    "\n",
    "    OUTDIR = \"Data/Clustering_Analysis/final_lineage_ids/tonsil_vdjs_threshold_\" + str(thresholds[j])\n",
    "    CONTIGFILE = \"Data/Clustering_Analysis/igblast_filtered_annotated_preprocessed.tsv\"\n",
    "    SAMPLENAME= \"tonsil_vdjs\"\n",
    "    UNIQUE_VDJ_FILE=\"Data/Clustering_Analysis/cdr3_clusters/tonsil_vdjs_unique_vdjs_cdr3_clusters_threshold_\" + str(thresholds[j]) + \".tsv\"\n",
    "    #MATRIXFILES = args.matrixfiles\n",
    "    MATRIXDIR = \"Data/Clustering_Analysis/cdr3_clusters/\"\n",
    "    FRACTIONAL_CUTOFF = thresholds[j]\n",
    "\n",
    "    ####################################################################################################\n",
    "    def get_current_memory_usage():\n",
    "        ''' Memory usage in GB '''\n",
    "        with open('/proc/self/status') as memusage_file:\n",
    "            memusage = memusage_file.read().split('VmRSS:')[1].split('\\n')[0][:-3]\n",
    "        return int(memusage.strip())/1024/1024\n",
    "\n",
    "    ####################################################################################################\n",
    "\n",
    "    # read only unique vdjs first\n",
    "\n",
    "\n",
    "    start = time.time()\n",
    "    unique_vdjs = pd.read_table(UNIQUE_VDJ_FILE)\n",
    "\n",
    "    sys.stderr.write(\"Verifying that all distance matrices are available...\\n\")\n",
    "    for cluster_id in unique_vdjs.cluster_id.unique():\n",
    "        for s in ['v', 'j']:\n",
    "            BINARY_MATRIX_FILENAME = f'{MATRIXDIR}/{SAMPLENAME}_{cluster_id}_templated_{s}_threshold_{FRACTIONAL_CUTOFF}.npy'\n",
    "            if os.path.exists(BINARY_MATRIX_FILENAME):\n",
    "                pass\n",
    "            else:\n",
    "                sys.stderr.write(f\"Cannot find the following file {BINARY_MATRIX_FILENAME}. Aborting...\\n\")\n",
    "                sys.exit(1)\n",
    "\n",
    "    sys.stderr.write(f\"Clustering {unique_vdjs.shape[0]} unique variable sequences...\\n\")\n",
    "\n",
    "    unique_vdjs['templated_v'] = unique_vdjs.apply(lambda x: x.vdj_sequence[0:int(x.v_templated_len)], axis=1)\n",
    "    unique_vdjs['templated_j'] = unique_vdjs.apply(lambda x: x.vdj_sequence[-int(x.j_templated_len):], axis=1)\n",
    "    unique_vdjs['templated_vj'] = unique_vdjs['templated_v'] + \"+\" + unique_vdjs['templated_j']\n",
    "\n",
    "    TOTAL_LINEAGES = 0\n",
    "    unique_vdjs['lineage_id'] = -1\n",
    "\n",
    "    for cluster_id in unique_vdjs.cluster_id.value_counts().index:\n",
    "        subset = unique_vdjs[unique_vdjs['cluster_id'] == cluster_id]\n",
    "        IGH_flag = not subset[subset['locus'] == 'IGH'].empty\n",
    "\n",
    "        V_BINARY_MATRIX_FILENAME = f'{MATRIXDIR}/{SAMPLENAME}_{cluster_id}_templated_v_threshold_{FRACTIONAL_CUTOFF}.npy'\n",
    "        J_BINARY_MATRIX_FILENAME = f'{MATRIXDIR}/{SAMPLENAME}_{cluster_id}_templated_j_threshold_{FRACTIONAL_CUTOFF}.npy'\n",
    "    \n",
    "        templated_seqs = subset.templated_vj.values\n",
    "        n = len(templated_seqs)\n",
    "        subset_idx = subset.index\n",
    "\n",
    "        longest_templated_sequence = subset.templated_vj.str.len().max()\n",
    "\n",
    "        sys.stderr.write(\n",
    "            f\"Processing VDJ sequence subset: cluster_id={cluster_id}, n={n}\\n\")\n",
    "\n",
    "        Ds = np.load(V_BINARY_MATRIX_FILENAME, allow_pickle = False)\n",
    "        DJs = np.load(J_BINARY_MATRIX_FILENAME, allow_pickle = False)\n",
    "        \n",
    "        R = np.uint8(255) * np.ones((n,n), np.uint8) - Ds\n",
    "        Ds = Ds + DJs\n",
    "        Ds[R<DJs] = np.uint8(255)\n",
    "\n",
    "        n=Ds.shape[0]\n",
    "        diag_indices = np.diag_indices(n)\n",
    "        Ds[diag_indices] = np.uint8(255)\n",
    "        closest_d = np.min(Ds, axis=1)\n",
    "\n",
    "        Ds[diag_indices] = np.uint8(0)\n",
    "\n",
    "        if n > 1:\n",
    "            #cluster CDR3s\n",
    "            cutoff = np.uint8(FRACTIONAL_CUTOFF*longest_templated_sequence)\n",
    "            #Ds = ssd.squareform(Ds)\n",
    "            upper_triangular_indices = np.triu_indices(n, 1)\n",
    "            condensed_distance_matrix = Ds[upper_triangular_indices]\n",
    "\n",
    "            if FRACTIONAL_CUTOFF == 0.2 and IGH_flag: dist_list_VJ.extend((condensed_distance_matrix/longest_templated_sequence).tolist())\n",
    "\n",
    "            new_lineage_ids = get_cluster_ids(condensed_distance_matrix,\n",
    "                                            cutoff=cutoff,\n",
    "                                            method='single')\n",
    "        else:\n",
    "            new_lineage_ids = np.zeros(1)\n",
    "        unique_vdjs.loc[subset_idx, 'lineage_id'] = TOTAL_LINEAGES + new_lineage_ids\n",
    "        TOTAL_LINEAGES += max(new_lineage_ids) + 1\n",
    "\n",
    "        sys.stderr.write(f\"[{time.time() - start}s]  found {new_lineage_ids.max() + 1} new lineages...\\n\")\n",
    "\n",
    "    sys.stderr.write(f\"Clustering templated sequences took {round(time.time() - start)} seconds\\n\")\n",
    "\n",
    "\n",
    "    vdj_families = unique_vdjs[['vdj_sequence','lineage_id']].set_index('vdj_sequence').to_dict()\n",
    "    vdj_families = vdj_families['lineage_id']\n",
    "\n",
    "    # read whole dataframe and append lineage ids\n",
    "    df = pd.read_table(CONTIGFILE)\n",
    "    df['vdj_sequence'] = df.apply(lambda x: x.sequence[int(x.v_sequence_start)-1:\n",
    "                                        int(x.j_sequence_end)], axis = 1)\n",
    "\n",
    "    df['lineage_id'] = df.vdj_sequence.map(vdj_families)\n",
    "    df = df[df.lineage_id.notna()]\n",
    "\n",
    "    df.to_csv(f'{OUTDIR}.tsv', sep = '\\t', index = False)\n",
    "\n",
    "dist_list_VJ = np.array(dist_list_VJ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"Data/Preprocessed_Data/cluster_dists.pkl\"\n",
    "with open(fname, \"rb\") as f:\n",
    "    dist_lists = pickle.load(f)\n",
    "    dist_list_CDR3 = dist_lists[\"dist_list_CDR3\"]\n",
    "    dist_list_VJ = dist_lists[\"dist_list_VJ\"]\n",
    "\n",
    "x1, y1, y_err1 = pdf_histogram(dist_list_CDR3, np.linspace(0, 1, 30))\n",
    "x2, y2, y_err2 = pdf_histogram(dist_list_VJ, np.linspace(0, 0.3, 30))\n",
    "\n",
    "n_lineages_threshold = np.zeros(len(thresholds))\n",
    "all_lineage_sizes = []\n",
    "for j in range(len(thresholds)):\n",
    "    OUTDIR = \"Data/Clustering_Analysis/final_lineage_ids/tonsil_vdjs_threshold_\" + str(thresholds[j])\n",
    "    df = pd.read_table(f'{OUTDIR}.tsv')\n",
    "    n_lineages_threshold[j] = df[df['locus']=='IGH'].lineage_id.nunique()\n",
    "\n",
    "    lineage_sizes = np.array(df[df['locus']=='IGH'].groupby('lineage_id').size().values)\n",
    "    all_lineage_sizes.append(lineage_sizes)\n",
    "\n",
    "n_extra_bins = 10\n",
    "bin_edges = np.append(np.arange(1,10),np.exp(np.linspace(np.log(10),1+np.max(np.log(all_lineage_sizes[-1])),n_extra_bins)))\n",
    "bin_edges[9] = 10\n",
    "\n",
    "x3, y3, y_err3 = pdf_histogram(all_lineage_sizes[0], bin_edges)\n",
    "x4, y4, y_err4 = pdf_histogram(all_lineage_sizes[5], bin_edges)\n",
    "x5, y5, y_err5 = pdf_histogram(all_lineage_sizes[-1], bin_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "# First subplot: CDR3 and VJ distance distributions\n",
    "axs[0].plot(x1, y1, color='black', linewidth=3, label='CDR3 distance')\n",
    "#axs[0].plot(x2, y2, color='gray', linewidth=3, label='VJ distance after CDR3 clustering')\n",
    "axs[0].set_xlabel('Genetic distance')\n",
    "axs[0].set_ylabel('Probability density')\n",
    "axs[0].set_ylim([0.001, 21])\n",
    "axs[0].set_xlim([0, 1])\n",
    "axs[0].set_yscale('log')\n",
    "#axs[0].legend()\n",
    "axs[0].vlines(0.2, 0, 25, color='red', linestyle='--', linewidth=2, label='x = 0.2')\n",
    "\n",
    "# Second subplot: Number of lineages vs threshold\n",
    "axs[1].plot(thresholds, n_lineages_threshold, color='black', marker='o', linewidth=2, label='Number of lineages')\n",
    "axs[1].set_xlabel('Lineage clustering threshold')\n",
    "axs[1].set_ylabel('Number inferred lineages')\n",
    "axs[1].axvline(x=0.2, color='red', linestyle='--', linewidth=2, label='x = 0.2')\n",
    "axs[1].set_ylim([1, 10000])\n",
    "axs[1].set_yticks([1, 5000, 10000])\n",
    "axs[1].set_xticks([0.1, 0.2, 0.3])\n",
    "\n",
    "# Third subplot: Lineage size distributions for different thresholds\n",
    "axs[2].plot(x3 * np.random.normal(1, 0.05, size=len(x3)), y3, color=[0.2, 0.2, 0.8], linewidth=3, alpha=0.8, label='Threshold = 0.1', marker='o')\n",
    "axs[2].plot(x4 * np.random.normal(1, 0.05, size=len(x4)), y4, color=[0, 0, 0], linewidth=3, alpha=0.8, label='Threshold = 0.2', marker='o')\n",
    "axs[2].plot(x5 * np.random.normal(1, 0.05, size=len(x5)), y5, color=[0.8, 0.2, 0.2], linewidth=3, alpha=0.8, label='Threshold = 0.3', marker='o')\n",
    "axs[2].legend()\n",
    "axs[2].set_yscale('log')\n",
    "axs[2].set_xscale('log')\n",
    "axs[2].set_xlabel('Lineage size')\n",
    "axs[2].set_ylabel('Probability density')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(r'Figures\\Supplementary\\Lineage_Threshold.pdf', format='pdf')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'Data\\Preprocessed_Data/pairwise_distances.pickle'\n",
    "with open(fname, 'rb') as f:\n",
    "    pairwise_distances = pickle.load(f)\n",
    "    intra_dists = pairwise_distances['intra_dists']\n",
    "    all_inter_dists = pairwise_distances['all_inter_dists']\n",
    "    inter_dists = pairwise_distances['inter_dists']\n",
    "\n",
    "typ_intra_dist = np.median(intra_dists)\n",
    "\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "df_TRB_IF = df_TRB[\n",
    "    (df_TRB['Follicles_seurat'] != 'nonFoll') &\n",
    "    (df_TRB['Follicles_seurat'].apply(lambda x: isinstance(x, str)))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE S3: Further analysis of migration distances\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Label all spatial barcodes adjacent to extrafollicular regions\n",
    "near_cutoff = 700\n",
    "\n",
    "metadata_df['near_EF'] = metadata_df['Follicles_seurat'].apply(lambda x: x == 'nonFoll' or not isinstance(x, str))\n",
    "\n",
    "for section in metadata_df['section'].unique():\n",
    "    section_rows = metadata_df[metadata_df['section'] == section]\n",
    "    ef_mask = section_rows['near_EF'].values\n",
    "    ef_coords = section_rows.loc[ef_mask, ['x', 'y']].astype(float).values\n",
    "    all_coords = section_rows[['x', 'y']].astype(float).values\n",
    "\n",
    "    if len(ef_coords) == 0:\n",
    "        continue\n",
    "\n",
    "    dists = cdist(all_coords, ef_coords)\n",
    "    near_any_ef = (dists <= near_cutoff).any(axis=1)\n",
    "    indices_to_update = section_rows.index[near_any_ef]\n",
    "    metadata_df.loc[indices_to_update, 'near_EF'] = True\n",
    "\n",
    "df_IGH_inner = df_IGH_IF[df_IGH_IF['st_barcode'].isin(metadata_df[metadata_df['near_EF'] == False]['spatial_bc'])]\n",
    "\n",
    "fname = 'Data\\Preprocessed_Data/pairwise_distances.pickle'\n",
    "with open(fname, 'rb') as f:\n",
    "    pairwise_distances = pickle.load(f)\n",
    "    intra_dists = pairwise_distances['intra_dists']\n",
    "    all_inter_dists = pairwise_distances['all_inter_dists']\n",
    "    inter_dists = pairwise_distances['inter_dists']\n",
    "\n",
    "typ_intra_dist = np.median(intra_dists)\n",
    "\n",
    "all_inter_dists_inner = np.zeros(len(df_IGH_inner)**2)\n",
    "inter_dists_inner = np.zeros(len(df_IGH_inner)**2)\n",
    "all_inter_dists_crosssec = np.zeros(len(df_IGH_IF)**2)\n",
    "inter_dists_crosssec = np.zeros(len(df_IGH_IF)**2)\n",
    "k1 = 0\n",
    "k2 = 0\n",
    "\n",
    "grouped = df_IGH_inner.groupby('follicle')\n",
    "for name1, group1 in grouped:\n",
    "    for name2, group2 in grouped:\n",
    "        if name1 >= name2: continue\n",
    "        for i, row1 in group1.iterrows():\n",
    "            for j, row2 in group2.iterrows():\n",
    "                all_inter_dists_inner[k1] = euclidean_distance(row1, row2)\n",
    "                k1 += 1\n",
    "                if row1['lineage_id'] == row2['lineage_id']:\n",
    "                    inter_dists_inner[k2] = euclidean_distance(row1, row2)\n",
    "                    k2 += 1\n",
    "\n",
    "all_inter_dists_inner = all_inter_dists_inner[:k1]\n",
    "inter_dists_inner = inter_dists_inner[:k2]\n",
    "\n",
    "k1 = 0\n",
    "k2 = 0\n",
    "\n",
    "grouped = df_IGH_IF.groupby('follicle')\n",
    "for name1, group1 in grouped:\n",
    "    for name2, group2 in grouped:\n",
    "        if name1 >= name2: continue\n",
    "        for i, row1 in group1.iterrows():\n",
    "            for j, row2 in group2.iterrows():\n",
    "                if row1['section'] == row2['section']: continue\n",
    "                all_inter_dists_crosssec[k1] = euclidean_distance(row1, row2)\n",
    "                k1 += 1\n",
    "                if row1['lineage_id'] == row2['lineage_id']:\n",
    "                    inter_dists_crosssec[k2] = euclidean_distance(row1, row2)\n",
    "                    k2 += 1\n",
    "\n",
    "all_inter_dists_crosssec = all_inter_dists_crosssec[:k1]\n",
    "inter_dists_crosssec = inter_dists_crosssec[:k2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'Data\\Preprocessed_Data/pairwise_distances.pickle'\n",
    "with open(fname, 'rb') as f:\n",
    "    pairwise_distances = pickle.load(f)\n",
    "    intra_dists = pairwise_distances['intra_dists']\n",
    "    all_inter_dists = pairwise_distances['all_inter_dists']\n",
    "    inter_dists = pairwise_distances['inter_dists']\n",
    "\n",
    "typ_intra_dist = np.median(intra_dists)\n",
    "\n",
    "fname = 'Data\\Preprocessed_Data/pairwise_distances_misc.pickle'\n",
    "\n",
    "with open(fname, 'rb') as f:\n",
    "    pairwise_distances_misc = pickle.load(f)\n",
    "    all_inter_dists_inner = pairwise_distances_misc['all_inter_dists_inner']\n",
    "    inter_dists_inner = pairwise_distances_misc['inter_dists_inner']\n",
    "    all_inter_dists_crosssec = pairwise_distances_misc['all_inter_dists_crosssec']\n",
    "    inter_dists_crosssec = pairwise_distances_misc['inter_dists_crosssec']\n",
    "\n",
    "bin_edges = np.linspace(0,0.1+max(np.max(inter_dists_inner)/typ_intra_dist, np.max(all_inter_dists_inner)/typ_intra_dist),40)\n",
    "x_dist1, y_dist1, y_dist_err1 = pdf_histogram(inter_dists_inner/typ_intra_dist, bin_edges)\n",
    "x_dist2, y_dist2, y_dist_err2 = pdf_histogram(all_inter_dists_inner/typ_intra_dist, bin_edges)\n",
    "\n",
    "bin_edges = np.linspace(0,0.1+max(np.max(inter_dists_crosssec)/typ_intra_dist, np.max(all_inter_dists_crosssec)/typ_intra_dist),40)\n",
    "x_dist3, y_dist3, y_dist_err3 = pdf_histogram(inter_dists_crosssec/typ_intra_dist, bin_edges)\n",
    "x_dist4, y_dist4, y_dist_err4 = pdf_histogram(all_inter_dists_crosssec/typ_intra_dist, bin_edges)\n",
    "\n",
    "\n",
    "palette = sb.color_palette(\"colorblind\", 4)\n",
    "colors = [palette[0], palette[1]]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), sharey=True)\n",
    "\n",
    "ax1.plot(x_dist1, y_dist1, color=colors[0], label='Cross-follicle, within lineage', alpha=0.75, linewidth=3)\n",
    "ax1.plot(x_dist2, y_dist2, color=colors[1], label='Cross-follicle, all pairs', alpha=0.75, linewidth=3)\n",
    "ax1.set_xlabel('Euclidean distance')\n",
    "ax1.set_ylabel('Probability density')\n",
    "ax1.set_yticks([0, 0.1, 0.2, 0.3])\n",
    "ax1.set_ylim([0, 0.36])\n",
    "ax1.set_xlim([0, 10])\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(x_dist3, y_dist3, color=colors[0], label='Cross-follicle, within lineage', alpha=0.75, linewidth=3)\n",
    "ax2.plot(x_dist4, y_dist4, color=colors[1], label='Cross-follicle, all pairs', alpha=0.75, linewidth=3)\n",
    "ax2.set_xlabel('Euclidean distance (cross-section)')\n",
    "ax2.set_xlim([0, 10])\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.savefig(r'Figures\\Supplementary\\Locality_Analysis_With_Filtering.pdf', format='pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE S4: T cell spatial distribution\n",
    "\n",
    "fname = 'Data\\Preprocessed_Data/pairwise_distances.pickle'\n",
    "with open(fname, 'rb') as f:\n",
    "    pairwise_distances = pickle.load(f)\n",
    "    intra_dists = pairwise_distances['intra_dists']\n",
    "    all_inter_dists = pairwise_distances['all_inter_dists']\n",
    "    inter_dists = pairwise_distances['inter_dists']\n",
    "\n",
    "typ_intra_dist = np.median(intra_dists)\n",
    "\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "df_TRB_IF = df_TRB[\n",
    "    (df_TRB['Follicles_seurat'] != 'nonFoll') &\n",
    "    (df_TRB['Follicles_seurat'].apply(lambda x: isinstance(x, str)))\n",
    "]\n",
    "\n",
    "dist_list_full = []\n",
    "dist_list = []\n",
    "dist_list_avg = []\n",
    "for clone_id in df_TRB_IF['cloneId'].unique():\n",
    "    dist_list_temp = []\n",
    "    subset = df_TRB_IF[df_TRB_IF['cloneId'] == clone_id]\n",
    "    if len(subset) > 1:\n",
    "        for i, row1 in subset.iterrows():\n",
    "            for j, row2 in subset.iterrows():\n",
    "                if i <= j or row1['Follicles_seurat'] == row2['Follicles_seurat']: continue\n",
    "                dist = np.sqrt((row1['x'] - row2['x'])**2 + (row1['y'] - row2['y'])**2)\n",
    "                dist_list_temp.append(dist)\n",
    "    if len(dist_list_temp) > 0:\n",
    "        dist_list.extend(dist_list_temp)\n",
    "        dist_list_avg.append(np.mean(dist_list_temp))\n",
    "dist_list = np.array(dist_list)/typ_intra_dist\n",
    "dist_list_avg = np.array(dist_list_avg)/typ_intra_dist\n",
    "\n",
    "for foll in df_TRB_IF['Follicles_seurat'].unique():\n",
    "    for foll2 in df_TRB_IF['Follicles_seurat'].unique():\n",
    "        if foll >= foll2: continue\n",
    "        subset1 = df_TRB_IF[df_TRB_IF['Follicles_seurat'] == foll]\n",
    "        subset2 = df_TRB_IF[df_TRB_IF['Follicles_seurat'] == foll2]\n",
    "        for i, row1 in subset1.iterrows():\n",
    "            for j, row2 in subset2.iterrows():\n",
    "                dist = np.sqrt((row1['x'] - row2['x'])**2 + (row1['y'] - row2['y'])**2)\n",
    "                dist_list_full.append(dist)\n",
    "dist_list_full = np.array(dist_list_full)/typ_intra_dist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'Data\\Preprocessed_Data/T_cell_distance.pickle'\n",
    "with open(fname, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    dist_list_full = data['dist_list_full']\n",
    "    dist_list = data['dist_list']\n",
    "    dist_list_avg = data['dist_list_avg']\n",
    "\n",
    "bins = np.linspace(0, max(dist_list_full)+0.1, 50)\n",
    "bins2 = np.linspace(0, max(dist_list_full)+0.1, 25)\n",
    "\n",
    "x3, y3, _ = pdf_histogram(dist_list_full[dist_list_full>0], bins)\n",
    "x4, y4, _ = pdf_histogram(dist_list[dist_list>0], bins)\n",
    "x5, y5, _ = pdf_histogram(dist_list_avg[dist_list_avg>0], bins2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sb.color_palette(\"colorblind\", 4)\n",
    "colors = [palette[0], palette[1], palette[2], palette[3]]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "#plt.plot(x, y, color=colors[1], label='All T cell pairs',alpha=0.75,linewidth=3)\n",
    "#plt.plot(x2, y2, color=colors[0], label='T cell clones',alpha=0.75,linewidth=3)\n",
    "\n",
    "plt.plot(x4, y4, color=colors[0], label='Clonal UMI pairs',alpha=0.75,linewidth=3)\n",
    "plt.plot(x5, y5, color=[0.5,0.75,1], label='Clonal pairs, avg. across lineages',alpha=0.75,linewidth=3)\n",
    "\n",
    "plt.plot(x3, y3, color=colors[1], label='All UMI pairs',alpha=0.75,linewidth=3)\n",
    "\n",
    "plt.xlabel('Distance between spatial barcodes')\n",
    "plt.ylabel('T cell pair density')\n",
    "plt.legend()\n",
    "plt.xlim([0,13])\n",
    "plt.ylim([0,0.26])\n",
    "plt.yticks([0,0.1,0.2])\n",
    "\n",
    "plt.savefig(r'Figures\\Supplementary\\SI_T_Cell_Spatial.pdf', format='pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_clone_same = 0\n",
    "p_clone_overall = 0\n",
    "\n",
    "denom = 0\n",
    "\n",
    "grouped = df_TRB_IF.groupby('Follicles_seurat')\n",
    "for name, group in grouped:\n",
    "    clone_counts = np.array(group['cloneId'].value_counts())\n",
    "    p_clone_same += np.sum(clone_counts * (clone_counts - 1))\n",
    "    denom += np.sum(clone_counts) * (np.sum(clone_counts) - 1)\n",
    "p_clone_same /= denom\n",
    "\n",
    "clone_counts_all = np.array(df_TRB_IF['cloneId'].value_counts())\n",
    "p_clone_overall = np.sum(clone_counts_all * (clone_counts_all - 1))\n",
    "p_clone_overall /= np.sum(clone_counts_all) * (np.sum(clone_counts_all) - 1)\n",
    "\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "ax.bar(['Same GC', 'All UMI pairs'], [p_clone_same, p_clone_overall], color=['black', 'red'],alpha=0.75)\n",
    "ax.set_ylabel('Fraction clonal pairs')\n",
    "ax.set_ylim([0,0.0015])\n",
    "ax.set_yticks([0, 0.0005, 0.001, 0.0015])\n",
    "ax.set_yticklabels(['0%', '0.05%', '0.1%', '0.15%'])\n",
    "plt.savefig(r'Figures\\Supplementary\\T_Cell_Clone_Prob.pdf', format='pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE S5A: Plasma fraction distribution\n",
    "\n",
    "plasma_fracs_IF = metadata_df[(metadata_df['Follicles_seurat'] != 'nonFoll') & (metadata_df['Follicles_seurat'].apply(lambda x: isinstance(x, str)))]['plasma_frac']\n",
    "plasma_fracs_EF = metadata_df[(metadata_df['Follicles_seurat'] == 'nonFoll') | (metadata_df['Follicles_seurat'].apply(lambda x: not isinstance(x, str)))]['plasma_frac']\n",
    "\n",
    "bin_edges = np.linspace(0, 1, 20)\n",
    "\n",
    "x_dist1, y_dist1, y_dist_err1 = pdf_histogram(plasma_fracs_IF, bin_edges)\n",
    "x_dist2, y_dist2, y_dist_err2 = pdf_histogram(plasma_fracs_EF, bin_edges)\n",
    "\n",
    "\n",
    "plt.plot(x_dist1, y_dist1, 'gray', linewidth=3,label='Intrafollicular')\n",
    "plt.plot(x_dist2, y_dist2, 'black', linewidth=3,label='Extrafollicular')\n",
    "\n",
    "plt.xlabel('Plasma fraction')\n",
    "plt.ylabel('Probability density')\n",
    "plt.legend()\n",
    "plt.xlim([0,1])\n",
    "plt.yticks([0, 4, 8, 12])\n",
    "plt.ylim([0,14])\n",
    "\n",
    "plt.axvline(x=0.9, color=[0.3,0.3,0.7], linestyle='--', linewidth=2)\n",
    "\n",
    "plt.savefig(r'Figures\\Supplementary\\Plasma_Dom_Distribution.pdf', format='pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE S5B: Spatial location of plasmablasts\n",
    "\n",
    "section_df = metadata_df[metadata_df['section'] == '17']\n",
    "\n",
    "for _, row in section_df.iterrows():\n",
    "    x = float(row['x'])\n",
    "    y = float(row['y'])\n",
    "    if (row['Follicles_seurat'] != 'nonFoll' and isinstance(row['Follicles_seurat'], str)) or row['plasma_frac'] > 0.9: continue\n",
    "    plt.scatter(x, y, color=[0.7,0.7,0.7], s=20)\n",
    "\n",
    "for _, row in section_df.iterrows():\n",
    "    x = float(row['x'])\n",
    "    y = float(row['y'])\n",
    "    if (row['Follicles_seurat'] != 'nonFoll' and isinstance(row['Follicles_seurat'], str)) or row['plasma_frac'] <= 0.9: continue\n",
    "    plt.scatter(x, y, color=[0.3,0.3,0.7], s=20)\n",
    "\n",
    "for _, row in section_df.iterrows():\n",
    "    x = float(row['x'])\n",
    "    y = float(row['y'])\n",
    "    if (row['Follicles_seurat'] == 'nonFoll' or not isinstance(row['Follicles_seurat'], str)): continue\n",
    "    plt.scatter(x, y, color=[1,0.8,1], s=20)\n",
    "\n",
    "plt.gca().set_aspect('equal', 'box')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(r'Figures\\Supplementary\\Plasma_Dom_Visual.pdf', format='pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE S5C: Lineage age scales with plasmabalst relatives\n",
    "\n",
    "lineage_metrics = []\n",
    "for lineage_id in df_IGH_IF['lineage_id'].unique():\n",
    "    n_ef = len(df_IGH_EF_PBdom[df_IGH_EF_PBdom['lineage_id'] == lineage_id])\n",
    "    n_total = len(df_combined[df_combined['lineage_id'] == lineage_id])\n",
    "    ratio = n_ef / n_total\n",
    "\n",
    "    mean_div = np.mean([\n",
    "        int(row['v_mismatch']) / len(row['v_sequence_no_trunc'])\n",
    "        for _, row in df_IGH_IF[df_IGH_IF['lineage_id'] == lineage_id].iterrows()\n",
    "    ])\n",
    "    lineage_metrics.append([mean_div, ratio])\n",
    "lineage_metrics = np.array(lineage_metrics)\n",
    "\n",
    "bins = np.linspace(0,0.12,21)\n",
    "mean_divs = np.zeros(len(bins)-1)\n",
    "prop_EF = np.zeros(len(bins)-1)\n",
    "err_EF = np.zeros(len(bins)-1)\n",
    "for i in range(0,len(bins)-1):\n",
    "    mask = np.logical_and(lineage_metrics[:,0] >= bins[i], lineage_metrics[:,0] < bins[i+1])\n",
    "\n",
    "    mean_divs[i] = np.mean(lineage_metrics[mask,0])\n",
    "    prop_EF[i] = np.mean(lineage_metrics[mask,1])\n",
    "    err_EF[i] = np.std(lineage_metrics[mask,1]) / np.sqrt(np.sum(mask))\n",
    "\n",
    "plt.plot(mean_divs, prop_EF, color='black',marker='o')\n",
    "plt.fill_between(mean_divs, prop_EF - err_EF, prop_EF + err_EF, color='gray', alpha=0.3)\n",
    "\n",
    "plt.xticks([0,0.03,0.06,0.09,0.12], [r'$0\\%$', r'$3\\%$', r'$6\\%$', r'$9\\%$', r'$12\\%$'])\n",
    "plt.xlabel('Mean lineage divergence from root')\n",
    "plt.ylabel('Plasmablast proportion')\n",
    "plt.ylim([0,0.5])\n",
    "plt.xlim([0,0.12])\n",
    "\n",
    "plt.savefig(r'Figures\\Supplementary\\Lineage_Age_PBs.pdf', format='pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE S6: Clonal burst pairwise analysis\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "sequence_info = []\n",
    "for sequence in df_combined['v_sequence_no_trunc'].unique():\n",
    "    subset = df_combined[df_combined['v_sequence_no_trunc'] == sequence]\n",
    "    num_appearances = len(subset)\n",
    "    num_distinct_follicles = subset[subset['follicle'] != 'EF']['follicle'].nunique()\n",
    "    div_from_root = int(subset.iloc[0]['v_mismatch'])/len(sequence)\n",
    "    num_appearances_EF = len(subset[subset['follicle'] == 'EF'])\n",
    "\n",
    "    prob_distinct = 0\n",
    "    if num_distinct_follicles > 1:\n",
    "        foll_list = subset[subset['follicle'] != 'EF']['follicle'].unique()\n",
    "        for foll1 in range(len(foll_list)):\n",
    "            for foll2 in range(foll1+1, len(foll_list)):\n",
    "                prob_distinct += 2 * len(subset[subset['follicle'] == foll_list[foll1]])/(num_appearances - num_appearances_EF) * len(subset[subset['follicle'] == foll_list[foll2]])/(num_appearances - num_appearances_EF - 1)\n",
    "\n",
    "    sequence_info.append([sequence, num_appearances-num_appearances_EF, num_distinct_follicles, div_from_root, num_appearances_EF, prob_distinct])\n",
    "\n",
    "clonal_burst_df = pd.DataFrame(sequence_info, columns=['v_sequence_no_trunc', 'num_appearances_IF', 'num_distinct_follicles', 'div_from_root', 'num_appearances_EF', 'prob_distinct'])\n",
    "clonal_burst_df = clonal_burst_df[clonal_burst_df['num_appearances_IF'] + clonal_burst_df['num_appearances_EF'] >= 2]\n",
    "clonal_burst_df = clonal_burst_df[clonal_burst_df['div_from_root'] > 0.01]\n",
    "\n",
    "mask = clonal_burst_df['num_appearances_IF'] >= 2\n",
    "overall_prob = np.sum(clonal_burst_df[mask]['num_distinct_follicles'] > 1)/np.sum(mask)\n",
    "\n",
    "bins = np.array([2,3,4,5,6,7,8,9,10,15,20,30,40,60,80,100,120])\n",
    "x = np.zeros(len(bins)-1)\n",
    "prop_pairs_migrant = np.zeros(len(bins)-1)\n",
    "prop_pairs_migrant_err = np.zeros(len(bins)-1)\n",
    "\n",
    "for i in range(0,len(bins)-1):\n",
    "    mask = np.logical_and(clonal_burst_df['num_appearances_IF'] >= bins[i], clonal_burst_df['num_appearances_IF'] < bins[i+1])\n",
    "    prop_pairs_migrant[i] = np.mean(clonal_burst_df[mask]['prob_distinct'])\n",
    "    prop_pairs_migrant_err[i] = np.std(clonal_burst_df[mask]['prob_distinct'])/np.sqrt(np.sum(mask))\n",
    "    x[i] = np.mean(clonal_burst_df[mask]['num_appearances_IF'])\n",
    "\n",
    "\n",
    "plt.errorbar(x, prop_pairs_migrant, prop_pairs_migrant_err, marker='o', linewidth=2, linestyle='none', markersize=7, color='black', capsize=5)\n",
    "plt.ylim([0,1])\n",
    "plt.xscale('log')\n",
    "plt.xticks([2, 3, 5,10, 20, 30, 50, 100], ['2', '3','5', '10', '20', '30','50', '100'])\n",
    "plt.xlabel('Clonal burst size')\n",
    "plt.ylabel('Frac. cross-follicle pairs in burst')\n",
    "\n",
    "plt.savefig(r'Figures\\Supplementary\\Clonal_Burst_Pairwise.pdf', format='pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE S7A: Power law distributions of lineage sizes\n",
    "\n",
    "foll_stats = df_IGH_IF.groupby('follicle').agg(\n",
    "    n_UMIs = ('follicle','size'),\n",
    "    n_clones = ('vdj_sequence', 'nunique'),\n",
    "    n_lineages = ('lineage_id', 'nunique')\n",
    ").reset_index()\n",
    "foll_stats = foll_stats.sort_values(by='n_UMIs', ascending=False)\n",
    "\n",
    "EF_stats = np.array([len(df_IGH_EF), df_IGH_EF['vdj_sequence'].nunique(), df_IGH_EF['lineage_id'].nunique()])\n",
    "\n",
    "lineage_stats = df_IGH_IF.groupby('lineage_id').agg(\n",
    "    n_UMIs=('lineage_id', 'size'),\n",
    "    n_follicles=('follicle', 'nunique'),\n",
    "    n_vdjs = ('vdj_sequence', 'nunique')\n",
    ").reset_index()\n",
    "\n",
    "ef_counts = df_IGH_EF['lineage_id'].value_counts().rename('EF_UMIs').reset_index()\n",
    "ef_counts.columns = ['lineage_id', 'EF_UMIs']\n",
    "\n",
    "ef_vdjs = df_IGH_EF.groupby('lineage_id')['vdj_sequence'].nunique().reset_index().rename(columns={'vdj_sequence': 'EF_VDJs'})\n",
    "ef_counts = ef_counts.merge(ef_vdjs, on='lineage_id', how='left').fillna(0)\n",
    "ef_counts['EF_VDJs'] = ef_counts['EF_VDJs'].astype(int)\n",
    "\n",
    "lineage_stats = lineage_stats.merge(ef_counts, on='lineage_id', how='left').fillna(0)\n",
    "lineage_stats['EF_UMIs'] = lineage_stats['EF_UMIs'].astype(int)\n",
    "lineage_stats['EF_VDJs'] = lineage_stats['EF_VDJs'].astype(int)\n",
    "\n",
    "n_extra_bins = 10\n",
    "bin_edges = np.append(np.arange(1,10),np.exp(np.linspace(np.log(10),1+np.max(np.log(lineage_stats['n_UMIs'])),n_extra_bins)))\n",
    "bin_edges[9] = 10\n",
    "\n",
    "x_all, y_all, y_err_all = pdf_histogram(lineage_stats['n_UMIs'], bin_edges)\n",
    "x_1, y_1, y_err_1 = pdf_histogram(lineage_stats[lineage_stats['n_follicles'] == 1]['n_UMIs'], bin_edges)\n",
    "x_2, y_2, y_err_2 = pdf_histogram(lineage_stats[lineage_stats['n_follicles'] == 2]['n_UMIs'], bin_edges)\n",
    "x_3, y_3, y_err_3 = pdf_histogram(lineage_stats[lineage_stats['n_follicles'] == 3]['n_UMIs'], bin_edges)\n",
    "x_4, y_4, y_err_4 = pdf_histogram(lineage_stats[lineage_stats['n_follicles'] >= 4]['n_UMIs'], bin_edges)\n",
    "\n",
    "palette = sb.color_palette(\"colorblind\", 4)\n",
    "colors = [palette[0], palette[1], palette[2], palette[3]]\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(x_all, y_all, marker='o', color='black', label='All',alpha=0.75, linewidth=4)\n",
    "\n",
    "popt_all, _ = curve_fit(single_power_law_pdf, x_all, np.log(y_all), p0=2.)\n",
    "alpha_all = popt_all[0]\n",
    "y_fit_all = single_power_law_pdf(x_all, alpha_all, logY=False)\n",
    "print('alpha =', alpha_all)\n",
    "\n",
    "plt.plot(x_all, y_fit_all, color=[0.8,0,0.8], linestyle='--', linewidth=2)\n",
    "\n",
    "plt.plot(x_1, y_1, marker='o', color=colors[0], label='1-follicle',alpha=0.75, linewidth=4)\n",
    "plt.plot(x_2, y_2, marker='o', color=colors[1], label='2-follicle',alpha=0.75,linewidth=4)\n",
    "plt.plot(x_3, y_3, marker='o', color=colors[2], label='3-follicle',alpha=0.75,linewidth=4)\n",
    "plt.plot(x_4, y_4, marker='o', color='gray', label='4+-follicle',alpha=0.75,linewidth=4)\n",
    "\n",
    "plt.xlabel('Number of UMIs')\n",
    "plt.ylabel('Probability density')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "#plt.gca().add_patch(plt.Rectangle((0.9, 10**-3.5), 9.3, 1.2 - 10**-3.5, fill=False, edgecolor='gray', linewidth=1,linestyle='--'))\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.yticks([])\n",
    "\n",
    "#plt.savefig(r'Figures\\Supplementary\\Full_Power_Laws.pdf', format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE S7B: Overlapping power law fit\n",
    "\n",
    "x_for_fit = np.append(np.append(x_1[:9],x_2[:8]),x_3[:7])\n",
    "y_for_fit = np.append(np.append(y_1[:9],y_2[:8]),y_3[:7])\n",
    "popt, pcov = curve_fit(power_law_combined_pdf, x_for_fit, np.log(y_for_fit), p0=2.)\n",
    "alpha = popt[0]\n",
    "print(alpha)\n",
    "\n",
    "y_fit = power_law_combined_pdf(x_for_fit, alpha, logY=False, cond_adj = False)\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.plot(x_1[:9]*np.random.normal(1,0.05,size=9), y_1[:9], marker='o', color=colors[0], label='1-follicle',linestyle='none',markersize=7)\n",
    "plt.plot(x_2[:8]*np.random.normal(1,0.05,size=8), y_2[:8]*(1-y_fit[0]), marker='o', color=colors[1], label='2-follicle',linestyle='none',markersize=7)\n",
    "plt.plot(x_3[:7]*np.random.normal(1,0.05,size=7), y_3[:7]*(1-y_fit[0]-y_fit[1]), marker='o', color=colors[2], label='3-follicle',linestyle='none', markersize=7)\n",
    "\n",
    "\n",
    "plt.plot(x_for_fit[:9], y_fit[:9], color='black', linestyle='--')\n",
    "#plt.plot(x_for_fit[9:17], y_fit[9:17], color='black', linestyle='--')\n",
    "#plt.plot(x_for_fit[17:], y_fit[17:], color='black', linestyle='--')\n",
    "\n",
    "\n",
    "plt.xlabel('Number of UMIs')\n",
    "plt.ylabel('Scaled probability')\n",
    "\n",
    "plt.legend(loc = 'lower left')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.savefig(r'Figures\\Supplementary\\Overlapping_Power_Law.pdf', format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE S8: Survival functions with filtering and alternative models\n",
    "\n",
    "foll_names = df_IGH_IF['follicle'].unique()\n",
    "\n",
    "migration_count = np.zeros((len(lineage_ids), len(foll_names), len(foll_names)), dtype=int)\n",
    "migration_denoms = np.zeros((len(lineage_ids), len(foll_names)))\n",
    "branch_start_ends_mig = None\n",
    "\n",
    "for ind in range(len(lineage_ids)):\n",
    "\n",
    "    lin_id = int(float(lineage_ids[ind]))\n",
    "    tree = Phylo.read(\"Data/Lineage_Seqs/Lineage_Trees/tree_lin_\" + str(lin_id) + \"_no_ef.newick\", \"newick\")\n",
    "\n",
    "    root_flag = False\n",
    "    for clade in tree.find_clades():\n",
    "        if clade.name and clade.name.startswith(\"ROOT\"):\n",
    "            tree.root_with_outgroup(clade)\n",
    "            if clade.name == \"ROOT__INFERRED\": tree.collapse(clade)\n",
    "            root_flag = True\n",
    "            break\n",
    "    if not root_flag: print(\"Error: No root found\")\n",
    "\n",
    "    label_tips(tree, df_IGH_IF, lineage_ids[ind], ignore_EF = True)\n",
    "    fill_internal_nodes(tree, lineage_ids[ind], df_IGH_IF, track_dominant = True)\n",
    "\n",
    "    #visualize_tree(tree, df_IGH_IF, lineage_ids[ind], ignore_EF = True, use_internal_nodes=True)\n",
    "\n",
    "    branches = get_branch_annotations(tree)\n",
    "\n",
    "    tot_migrations = 0\n",
    "    tot_branch_len = 0\n",
    "    for branch in branches:\n",
    "        if branch['branch_length'] == 0: continue\n",
    "\n",
    "        par_ind = np.argmax(foll_names == branch['parent_foll'])\n",
    "        child_ind = np.argmax(foll_names == branch['child_foll'])\n",
    "        migration_denoms[ind, par_ind] += branch['branch_length']\n",
    "\n",
    "        if branch['parent_foll'] != branch['child_foll']:\n",
    "            migration_count[ind,par_ind,child_ind] += 1\n",
    "            branch_data = np.array([branch['parent_depth'], branch['parent_depth']+branch['branch_length'], 1])\n",
    "        else:\n",
    "            branch_data = np.array([branch['parent_depth'], branch['parent_depth']+branch['branch_length'], 0])\n",
    "\n",
    "        if branch_start_ends_mig is None:\n",
    "            branch_start_ends_mig = branch_data\n",
    "        else:\n",
    "            branch_start_ends_mig = np.vstack((branch_start_ends_mig, branch_data))\n",
    "\n",
    "lin_denoms = np.sum(migration_denoms, axis=1)\n",
    "migration_ct_lins = np.sum(migration_count, axis=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_ct = np.sum(migration_count,axis=(1,2))\n",
    "tot_denom = np.sum(migration_denoms,axis=1)\n",
    "frac_monofoll = np.sum(tot_ct == 0) / len(tot_ct)\n",
    "\n",
    "filt = tot_ct >= 1\n",
    "\n",
    "tot_ct = tot_ct[filt]\n",
    "tot_denom = tot_denom[filt]\n",
    "\n",
    "tau_ests1 = np.zeros((len(tot_ct), 3))\n",
    "\n",
    "for i in range(len(tot_ct)): tau_ests1[i] = poiss_CI(tot_ct[i], tot_denom[i])\n",
    "\n",
    "tot_ct = np.sum(migration_count,axis=(0,2))\n",
    "tot_denom = np.sum(migration_denoms,axis=0)\n",
    "filt = tot_ct >= 1\n",
    "\n",
    "tot_ct = tot_ct[filt]\n",
    "tot_denom = tot_denom[filt]\n",
    "\n",
    "tau_ests2 = np.zeros((len(tot_ct), 3))\n",
    "\n",
    "for i in range(len(tot_ct)): tau_ests2[i] = poiss_CI(tot_ct[i], tot_denom[i])\n",
    "\n",
    "rate_values = 1/tau_ests1[:,0]\n",
    "rate_inferred = fit_survival_func_single_rate(rate_values, lin_denoms, np.exp(np.mean(np.log(rate_values))), points_side = 20, plot_fit = False)\n",
    "\n",
    "x_vals = np.logspace(np.log10(rate_values.min()), np.log10(rate_values.max()), 500)\n",
    "surv_sampled_mean, surv_sampled_std, frac_monofoll_sampled, mig_numbers_sampled = get_survival_func_single_rate(lin_denoms, rate_inferred, x_vals)\n",
    "\n",
    "rates_data_sorted, survival_data = surv_func(rate_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_range = np.linspace(0,2,21)*rate_inferred\n",
    "N_trials = 10\n",
    "\n",
    "single_rate_err = np.zeros((len(std_range),N_trials))\n",
    "\n",
    "for j in range(0,N_trials):\n",
    "\n",
    "    all_x_vals_gamma = np.zeros((500, len(std_range)))\n",
    "    all_gamma_surv_sampled_mean = np.zeros((500, len(std_range)))\n",
    "    all_gamma_surv_sampled_std = np.zeros((500, len(std_range)))\n",
    "    all_survival_data_gamma_interp = np.zeros((500, len(std_range)))\n",
    "\n",
    "\n",
    "    for i in range(0,len(std_range)):\n",
    "        denoms_adj = np.copy(lin_denoms)\n",
    "        if std_range[i] > 0: denoms_adj *= np.random.gamma(rate_inferred**2/std_range[i]**2, std_range[i]**2/rate_inferred, len(denoms_adj))/rate_inferred\n",
    "        sampled_gamma_rates = np.random.poisson(denoms_adj*rate_inferred)/lin_denoms\n",
    "        sampled_gamma_rates_filt = sampled_gamma_rates[sampled_gamma_rates > 0]\n",
    "\n",
    "        gamma_rate_inferred = fit_survival_func_single_rate(sampled_gamma_rates_filt, lin_denoms, np.exp(np.mean(np.log(sampled_gamma_rates_filt))), points_side=20, plot_fit=False)\n",
    "\n",
    "        x_vals_gamma = np.logspace(np.log10(sampled_gamma_rates_filt.min()), np.log10(sampled_gamma_rates_filt.max()), 500)\n",
    "        gamma_surv_sampled_mean, gamma_surv_sampled_std, _, _ = get_survival_func_single_rate(lin_denoms, gamma_rate_inferred, x_vals_gamma)\n",
    "\n",
    "        rates_data_sorted_gamma, survival_data_gamma = surv_func(sampled_gamma_rates_filt)\n",
    "\n",
    "        interp_survival_gamma = interp1d(rates_data_sorted_gamma, survival_data_gamma, bounds_error=False, fill_value=\"extrapolate\")\n",
    "        survival_data_gamma_interp = interp_survival_gamma(x_vals_gamma)\n",
    "\n",
    "        all_x_vals_gamma[:,i] = x_vals_gamma\n",
    "        all_gamma_surv_sampled_mean[:,i] = gamma_surv_sampled_mean\n",
    "        all_gamma_surv_sampled_std[:,i] = gamma_surv_sampled_std\n",
    "        all_survival_data_gamma_interp[:,i] = survival_data_gamma_interp\n",
    "\n",
    "        single_rate_err[i,j] = np.mean((all_survival_data_gamma_interp[:,i] - all_gamma_surv_sampled_mean[:,i])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoms_adj = np.copy(lin_denoms)\n",
    "denoms_adj *= np.random.exponential(rate_inferred,len(denoms_adj))/rate_inferred\n",
    "sampled_expon_rates = np.random.poisson(denoms_adj*rate_inferred)/lin_denoms\n",
    "sampled_expon_rates_filt = sampled_expon_rates[sampled_expon_rates > 0]\n",
    "\n",
    "expon_rate_inferred = fit_survival_func_single_rate(sampled_expon_rates_filt, lin_denoms, np.exp(np.mean(np.log(sampled_expon_rates_filt))), points_side = 20, plot_fit = False)\n",
    "\n",
    "x_vals_expon = np.logspace(np.log10(sampled_expon_rates_filt.min()), np.log10(sampled_expon_rates_filt.max()), 500)\n",
    "expon_surv_sampled_mean, expon_surv_sampled_std, _, _ = get_survival_func_single_rate(lin_denoms, expon_rate_inferred, x_vals_expon)\n",
    "\n",
    "rates_data_sorted_expon, survival_data_expon = surv_func(sampled_expon_rates_filt)\n",
    "\n",
    "interp_survival_expon = interp1d(rates_data_sorted_expon, survival_data_expon, bounds_error=False, fill_value=\"extrapolate\")\n",
    "survival_data_expon_interp = interp_survival_expon(x_vals_expon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plt.plot(rates_data_sorted_expon, survival_data_expon, color='blue', label='Simulated data with variable rates', linewidth=4)\n",
    "plt.plot(x_vals_expon, expon_surv_sampled_mean, color='red', linewidth=1.5, label='Best-fit single rate')\n",
    "plt.fill_between(x_vals_expon, expon_surv_sampled_mean - expon_surv_sampled_std, expon_surv_sampled_mean + expon_surv_sampled_std, color='red', alpha=0.3)\n",
    "plt.xscale('log')\n",
    "plt.ylim([0, 1])\n",
    "plt.xticks([1, 10, 100, 1000], [r'$(100\\%)^{-1}$', r'$(10\\%)^{-1}$', r'$(1\\%)^{-1}$', r'$(0.1\\%)^{-1}$'])\n",
    "plt.xlabel('Migration rate (1/percent divergence)')\n",
    "plt.ylabel('Survival function')\n",
    "\n",
    "#plt.savefig(r'Figures\\Supplementary\\SI_Inferred_Rate_Survival.pdf', format='pdf')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "tot_ct = np.sum(migration_count,axis=(1,2))\n",
    "tot_denom = np.sum(migration_denoms,axis=1)\n",
    "filt = tot_ct >= 1\n",
    "\n",
    "err_bar_filt = np.logical_and(tot_ct[filt] < 2, 1/tau_ests1[:,0] > np.percentile(1/tau_ests1[:,0],90))\n",
    "\n",
    "tot_denom = np.sum(migration_denoms,axis=1)\n",
    "all_filt = np.ones(len(tot_ct), dtype=bool)\n",
    "ct = 0\n",
    "for i in range(len(tot_ct)):\n",
    "    if filt[i]:\n",
    "        if err_bar_filt[ct]: all_filt[i] = False\n",
    "        ct += 1\n",
    "mig_denoms_filt = tot_denom[all_filt]\n",
    "\n",
    "rate_values_filt = 1/tau_ests1[np.logical_not(err_bar_filt),0]\n",
    "\n",
    "rate_inferred_filt = fit_survival_func_single_rate(rate_values_filt, mig_denoms_filt, np.exp(np.mean(np.log(rate_values_filt))), points_side=20, plot_fit=False)\n",
    "\n",
    "x_vals_filt = np.logspace(np.log10(rate_values_filt.min()), np.log10(rate_values_filt.max()), 500)\n",
    "surv_sampled_mean_filt, surv_sampled_std_filt, _, _ = get_survival_func_single_rate(mig_denoms_filt, rate_inferred_filt, x_vals_filt)\n",
    "\n",
    "rates_data_sorted_filt, survival_data_filt = surv_func(rate_values_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked = np.where(np.isfinite(np.sqrt(single_rate_err)), np.sqrt(single_rate_err), np.nan)\n",
    "\n",
    "mean_err = np.nanmean(masked, axis=1)\n",
    "std_err  = np.nanstd(masked, axis=1)\n",
    "\n",
    "interp_filtered_data = interp1d(rates_data_sorted_filt, survival_data_filt, bounds_error=False, fill_value=\"extrapolate\")\n",
    "filtered_data_interp = interp_filtered_data(x_vals_filt)\n",
    "RMSE_data_filt = np.sqrt(np.mean((filtered_data_interp - surv_sampled_mean_filt)**2))\n",
    "\n",
    "plt.plot(std_range/rate_inferred, mean_err,color='black')\n",
    "plt.fill_between(std_range/rate_inferred, mean_err - std_err, mean_err + std_err, color='gray', alpha=0.3)\n",
    "\n",
    "plt.plot([0,2],[RMSE_data_filt, RMSE_data_filt],color='red',linestyle='--',linewidth=2)\n",
    "plt.ylabel('RMSE of single-rate prediction')\n",
    "plt.xlabel('CV(Migration rates)')\n",
    "plt.ylim([0,0.08])\n",
    "plt.xlim([0,2])\n",
    "plt.yticks([0,0.04,0.08])\n",
    "plt.xticks([0,0.5,1,1.5,2])\n",
    "\n",
    "#plt.savefig(r'Figures\\Supplementary\\SI_Rate_Variation_Power_Analysis.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE S9: Filtering out putative clonal bursts\n",
    "\n",
    "plt.ylim([1,250])\n",
    "plt.yscale('log')\n",
    "plt.yticks([100/50,100/10, 100/3, 100/1], [r'$(50\\%)^{-1}$',r'$(10\\%)^{-1}$',r'$(3\\%)^{-1}$', r'$(1\\%)^{-1}$'])\n",
    "filt_cutoff = np.percentile(1/tau_ests1[:,0],90)\n",
    "plt.gca().add_patch(plt.Rectangle((0.72, filt_cutoff), 0.7, 238 - filt_cutoff, color='green', alpha=0.2))\n",
    "rect = plt.Rectangle((0.72, filt_cutoff), 0.7, 238 - filt_cutoff, fill=False, edgecolor='darkgreen', linewidth=3, linestyle='--')\n",
    "plt.gca().add_patch(rect)\n",
    "plt.scatter(tot_ct[filt], 1/tau_ests1[:,0],color='black',alpha=0.2)\n",
    "plt.xscale('log')\n",
    "plt.xticks([1,2,5,10,15],['1','2','5','10','15'])\n",
    "plt.xlim([0.7,19])\n",
    "\n",
    "plt.xlabel('Number of migration events in lineage')\n",
    "plt.ylabel('Inferred migration rate (1/percent divergence)')\n",
    "\n",
    "plt.savefig(r'Figures\\Supplementary\\SI_Clonal_Burst_Filtering.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE S10A: Spatial distribution of early migrations\n",
    "\n",
    "fname = 'Data/Preprocessed_Data/pairwise_distances.pickle'\n",
    "with open(fname, 'rb') as f:\n",
    "    pairwise_distances = pickle.load(f)\n",
    "    intra_dists = pairwise_distances['intra_dists']\n",
    "    all_inter_dists = pairwise_distances['all_inter_dists']\n",
    "    inter_dists = pairwise_distances['inter_dists']\n",
    "\n",
    "typ_intra_dist = np.median(intra_dists)\n",
    "\n",
    "all_inter_dists_early = np.zeros(len(df_IGH_IF)**2)\n",
    "inter_dists_early = np.zeros(len(df_IGH_IF)**2)\n",
    "k1 = 0\n",
    "k2 = 0\n",
    "\n",
    "grouped = df_IGH_IF.groupby('follicle')\n",
    "for name1, group1 in grouped:\n",
    "    for name2, group2 in grouped:\n",
    "        if name1 >= name2: continue\n",
    "        for i, row1 in group1.iterrows():\n",
    "            div_from_root = int(row1['v_mismatch'])/len(row1['v_sequence_no_trunc'])\n",
    "            if div_from_root >= 0.01: continue\n",
    "            for j, row2 in group2.iterrows():\n",
    "                div_from_root = int(row2['v_mismatch'])/len(row2['v_sequence_no_trunc'])\n",
    "                if div_from_root >= 0.01: continue\n",
    "                all_inter_dists_early[k1] = euclidean_distance(row1, row2)\n",
    "                k1 += 1\n",
    "                if row1['lineage_id'] == row2['lineage_id']:\n",
    "                    inter_dists_early[k2] = euclidean_distance(row1, row2)\n",
    "                    k2 += 1\n",
    "\n",
    "all_inter_dists_early = all_inter_dists_early[:k1]\n",
    "inter_dists_early = inter_dists_early[:k2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "fname = 'Data\\Preprocessed_Data/pairwise_distances.pickle'\n",
    "with open(fname, 'rb') as f:\n",
    "    pairwise_distances = pickle.load(f)\n",
    "    intra_dists = pairwise_distances['intra_dists']\n",
    "    all_inter_dists = pairwise_distances['all_inter_dists']\n",
    "    inter_dists = pairwise_distances['inter_dists']\n",
    "\n",
    "typ_intra_dist = np.median(intra_dists)\n",
    "\n",
    "fname = 'Data\\Preprocessed_Data/pairwise_distances_early_migrations.pickle'\n",
    "\n",
    "with open(fname, 'rb') as f:\n",
    "    pairwise_distances_cb = pickle.load(f)\n",
    "    all_inter_dists_early = pairwise_distances_cb['all_inter_dists_early']\n",
    "    inter_dists_early = pairwise_distances_cb['inter_dists_early']\n",
    "\n",
    "bin_edges = np.linspace(0,0.1+max(np.max(inter_dists_early)/typ_intra_dist, np.max(all_inter_dists_early)/typ_intra_dist),20)\n",
    "\n",
    "x_dist1, y_dist1, y_dist_err1 = pdf_histogram(inter_dists_early/typ_intra_dist, bin_edges)\n",
    "x_dist2, y_dist2, y_dist_err2 = pdf_histogram(all_inter_dists_early/typ_intra_dist, bin_edges)\n",
    "\n",
    "palette = sb.color_palette(\"colorblind\", 4)\n",
    "colors = [palette[0], palette[1]]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.plot(x_dist1, y_dist1, color=colors[0], label='Between follicles, same clone',alpha=0.75,linewidth=3)\n",
    "plt.plot(x_dist2, y_dist2, color=colors[1], label='Between follicles, all pairs',alpha=0.75,linewidth=3)\n",
    "\n",
    "\n",
    "plt.xlabel('Euclidean distance between spatial barcodes')\n",
    "plt.ylabel('Probability density')\n",
    "plt.legend()\n",
    "plt.ylim([0,0.25])\n",
    "plt.yticks([0,0.1,0.2])\n",
    "#plt.xlim([0,10])\n",
    "\n",
    "plt.savefig(r'Figures\\Supplementary\\Early_Migrations_Spatial.pdf', format='pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE S10B: Diversification after migration, filtering out early migrations\n",
    "\n",
    "subtree_divs = []\n",
    "shuffled_divs = []\n",
    "\n",
    "subtree_descendants = []\n",
    "shuffled_descendants = []\n",
    "\n",
    "subtree_depths = []\n",
    "shuffled_depths = []\n",
    "\n",
    "N_randomizations = 100\n",
    "\n",
    "for ind in range(len(lineage_ids)):\n",
    "\n",
    "    lin_id = int(float(lineage_ids[ind]))\n",
    "    tree = Phylo.read(\"Data/Lineage_Seqs/Lineage_Trees/tree_lin_\" + str(lin_id) + \"_no_ef.newick\", \"newick\")\n",
    "\n",
    "    root_flag = False\n",
    "    for clade in tree.find_clades():\n",
    "        if clade.name and clade.name.startswith(\"ROOT\"):\n",
    "            tree.root_with_outgroup(clade)\n",
    "            if clade.name == \"ROOT__INFERRED\": tree.collapse(clade)\n",
    "            root_flag = True\n",
    "            break\n",
    "    if not root_flag: print(\"Error: No root found\")\n",
    "\n",
    "    label_tips(tree, df_IGH_IF, lineage_ids[ind], ignore_EF = True)\n",
    "    fill_internal_nodes(tree, lineage_ids[ind], df_IGH_IF, track_dominant = True)\n",
    "\n",
    "    subtree_div, subtree_desc, subtree_depth = get_subtree_data(tree, cutoff = 0, div_cutoff = 0.01)\n",
    "\n",
    "    subtree_divs.extend(subtree_div)\n",
    "    subtree_descendants.extend(subtree_desc)\n",
    "    subtree_depths.extend(subtree_depth)\n",
    "    \n",
    "    for j in range(N_randomizations):\n",
    "        tree_rand = randomize_migration_locations(tree)\n",
    "        subtree_div, subtree_desc, subtree_depth = get_subtree_data(tree_rand, cutoff = 0, div_cutoff = 0.01)\n",
    "\n",
    "        shuffled_divs.extend(subtree_div)\n",
    "        shuffled_descendants.extend(subtree_desc)\n",
    "        shuffled_depths.extend(subtree_depth)\n",
    "\n",
    "subtree_divs = np.array(subtree_divs)\n",
    "shuffled_divs = np.array(shuffled_divs)\n",
    "subtree_descendants = np.array(subtree_descendants)\n",
    "shuffled_descendants = np.array(shuffled_descendants)\n",
    "subtree_depths = np.array(subtree_depths)\n",
    "shuffled_depths = np.array(shuffled_depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = survival_func(subtree_divs[subtree_divs > 0])\n",
    "x2, y2 = survival_func(shuffled_divs[shuffled_divs > 0])\n",
    "\n",
    "zero_ct1 = np.sum(subtree_divs == 0)/len(subtree_divs)\n",
    "zero_ct2 = np.sum(shuffled_divs == 0)/len(shuffled_divs)\n",
    "\n",
    "plt.plot(x2[y2>0], y2[y2>0],color='red',label='Shuffled',linewidth=3,alpha=0.75)\n",
    "\n",
    "plt.plot(x1[y1>0], y1[y1>0],color='black',label='Data',linewidth=3,alpha=0.75)\n",
    "plt.xscale('log')\n",
    "#plt.yscale('log')\n",
    "plt.xlabel('Subtree phylogenetic divergence, x')\n",
    "plt.xticks([0.001,0.01,0.1,1],['0.1%','1%','10%','100%'])\n",
    "plt.ylabel('Survival function, P(div. > x | div. > 0)')\n",
    "plt.ylim([0,1])\n",
    "plt.legend()\n",
    "plt.savefig(r'Figures\\Supplementary\\Subtree_Divergence_Filtered.pdf', format='pdf')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "ax.bar(['Data', 'Shuffled'], [zero_ct1, zero_ct2], color=['black', 'red'],alpha=0.75)\n",
    "ax.set_ylabel('Fraction zero')\n",
    "ax.set_ylim([0,1])\n",
    "plt.savefig(r'Figures\\Supplementary\\Subtree_Divergence_Filtered_Inset.pdf', format='pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE S10C-D: Immigrant lineage statistics after filtering out early migrations\n",
    "\n",
    "div_cutoff = 0.01\n",
    "\n",
    "freq_list = []\n",
    "first_entry_list = []\n",
    "\n",
    "folls = df_IGH_IF['follicle'].unique()\n",
    "N_UMI = np.zeros(len(folls))\n",
    "N_lineage = np.zeros(len(folls))\n",
    "\n",
    "max_f = np.zeros(len(folls))\n",
    "max_f_migrant = np.zeros(len(folls))\n",
    "max_f_id = np.empty(len(folls),dtype='str')\n",
    "\n",
    "prop_UMI_migrant = np.zeros(len(folls))\n",
    "prop_lineage_migrant = np.zeros(len(folls))\n",
    "\n",
    "for i in range(len(folls)):\n",
    "    df_foll = df_IGH_IF[df_IGH_IF['follicle'] == folls[i]]\n",
    "    N_UMI[i] = len(df_foll)\n",
    "\n",
    "    running_migrant_UMI = 0\n",
    "    running_migrant_lineage = 0\n",
    "    running_migrant_UMI_corr = 0\n",
    "    running_migrant_lineage_corr = 0\n",
    "    lineages = df_foll['lineage_id'].unique()\n",
    "    N_lineage[i] = len(lineages)\n",
    "\n",
    "    for lineage in lineages:\n",
    "        df_lin = df_foll[df_foll['lineage_id'] == lineage]\n",
    "        if len(df_lin)/N_UMI[i] > max_f[i]:\n",
    "            max_f[i] = len(df_lin)/N_UMI[i]\n",
    "            max_f_id[i] = lineage\n",
    "\n",
    "        if df_lin['v_mutations'].nunique() <= 1: continue\n",
    "\n",
    "        lin_id = int(float(lineage))\n",
    "        tree = Phylo.read(\"Data/Lineage_Seqs/Lineage_Trees/tree_lin_\" + str(lin_id) + \"_no_ef.newick\", \"newick\")\n",
    "\n",
    "        root_flag = False\n",
    "        for clade in tree.find_clades():\n",
    "            if clade.name and clade.name.startswith(\"ROOT\"):\n",
    "                tree.root_with_outgroup(clade)\n",
    "                if clade.name == \"ROOT__INFERRED\": tree.collapse(clade)\n",
    "                root_flag = True\n",
    "                break\n",
    "        if not root_flag: print(\"Error: No root found\")\n",
    "\n",
    "        label_tips(tree, df_IGH, lineage, ignore_EF = True)\n",
    "        fill_internal_nodes(tree,lineage, df_IGH, track_dominant = True)\n",
    "\n",
    "        # Find all follicles in the tree with clades below div_cutoff depth\n",
    "        follicles_near_root = set()\n",
    "        for clade in tree.find_clades():\n",
    "            if tree.depths().get(clade) < div_cutoff:\n",
    "                follicles_near_root.add(clade.metadata['foll'])\n",
    "                for child in clade.clades: follicles_near_root.add(child.metadata['foll'])\n",
    "\n",
    "        if folls[i] not in follicles_near_root:\n",
    "            if len(df_lin)/N_UMI[i] > max_f_migrant[i]: max_f_migrant[i] = len(df_lin)/N_UMI[i]\n",
    "\n",
    "            prop_lineage_migrant[i] += 1/N_lineage[i]\n",
    "            prop_UMI_migrant[i] += len(df_lin)/N_UMI[i]\n",
    "\n",
    "            first_entry_list.append(find_first_entry(tree, folls[i]))\n",
    "            freq_list.append(len(df_lin)/N_UMI[i])\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "max_lineages = []\n",
    "for foll in df_IGH_IF['follicle'].unique():\n",
    "    df_foll = df_IGH_IF[df_IGH_IF['follicle'] == foll]\n",
    "    if not df_foll.empty:\n",
    "        lineage_counts = df_foll['lineage_id'].value_counts()\n",
    "        max_lineage = lineage_counts.idxmax()\n",
    "        max_lineages.append(max_lineage)\n",
    "\n",
    "counts = Counter(max_lineages)\n",
    "for lineage, count in counts.items():\n",
    "    if count > 1:\n",
    "        print(f\"{lineage}: {count}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(prop_lineage_migrant, prop_UMI_migrant, s=N_UMI, color='black',alpha=0.5)\n",
    "#plt.scatter(prop_lineage_migrant_corr_stats[1,:],prop_UMI_migrant_corr_stats[1,:],color=[0.7,0.7,0.7])\n",
    "plt.xlabel('Prop. immigrant lineages')\n",
    "plt.ylabel('Prop. immigrant UMIs')\n",
    "plt.xlim([0,0.08])\n",
    "plt.ylim([0,0.25])\n",
    "plt.savefig(r'Figures\\Supplementary\\Prop_Immigrants_Filtered.pdf', format='pdf')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(max_f, max_f_migrant,color='black',s=N_UMI,alpha=0.5)\n",
    "plt.plot([0,0.4],[0,0.4],color='gray',linestyle='--')\n",
    "plt.xlabel('Max. lineage frequency')\n",
    "plt.ylabel('Max. immigrant lineage frequency')\n",
    "plt.ylim([0,0.2])\n",
    "plt.xlim([0,0.4])\n",
    "plt.xticks([0,0.1,0.2,0.3,0.4])\n",
    "plt.yticks([0,0.1,0.2])\n",
    "plt.savefig(r'Figures\\Supplementary\\Max_Freq_Filtered.pdf', format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE S11: Additional subtree statistics\n",
    "\n",
    "subtree_divs = []\n",
    "shuffled_divs = []\n",
    "\n",
    "subtree_descendants = []\n",
    "shuffled_descendants = []\n",
    "\n",
    "subtree_depths = []\n",
    "shuffled_depths = []\n",
    "\n",
    "N_randomizations = 100\n",
    "\n",
    "for ind in range(len(lineage_ids)):\n",
    "\n",
    "    lin_id = int(float(lineage_ids[ind]))\n",
    "    tree = Phylo.read(\"Data/Lineage_Seqs/Lineage_Trees/tree_lin_\" + str(lin_id) + \"_no_ef.newick\", \"newick\")\n",
    "\n",
    "    root_flag = False\n",
    "    for clade in tree.find_clades():\n",
    "        if clade.name and clade.name.startswith(\"ROOT\"):\n",
    "            tree.root_with_outgroup(clade)\n",
    "            if clade.name == \"ROOT__INFERRED\": tree.collapse(clade)\n",
    "            root_flag = True\n",
    "            break\n",
    "    if not root_flag: print(\"Error: No root found\")\n",
    "\n",
    "    label_tips(tree, df_IGH, lineage_ids[ind], ignore_EF = True)\n",
    "    fill_internal_nodes(tree, lineage_ids[ind], df_IGH, track_dominant = True)\n",
    "\n",
    "    subtree_div, subtree_desc, subtree_depth = get_subtree_data(tree, cutoff = 0, div_cutoff = 0)\n",
    "    subtree_divs.extend(subtree_div)\n",
    "    subtree_descendants.extend(subtree_desc)\n",
    "    subtree_depths.extend(subtree_depth)\n",
    "    \n",
    "    for j in range(N_randomizations):\n",
    "        tree_rand = randomize_migration_locations(tree)\n",
    "        subtree_div, subtree_desc, subtree_depth = get_subtree_data(tree_rand, cutoff = 0)\n",
    "\n",
    "        shuffled_divs.extend(subtree_div)\n",
    "        shuffled_descendants.extend(subtree_desc)\n",
    "        shuffled_depths.extend(subtree_depth)\n",
    "\n",
    "subtree_divs = np.array(subtree_divs)\n",
    "shuffled_divs = np.array(shuffled_divs)\n",
    "subtree_descendants = np.array(subtree_descendants)\n",
    "shuffled_descendants = np.array(shuffled_descendants)\n",
    "subtree_depths = np.array(subtree_depths)\n",
    "shuffled_depths = np.array(shuffled_depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "x1, y1 = survival_func(subtree_descendants)\n",
    "x2, y2 = survival_func(shuffled_descendants)\n",
    "\n",
    "axes[0].plot(x1[y1>0], y1[y1>0], color='red', label='Data')\n",
    "axes[0].plot(x2[y2>0], y2[y2>0], color='black', label='Shuffled')\n",
    "axes[0].set_xlim([0, 75])\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].set_xlabel('Number of descendants after migration, x')\n",
    "axes[0].set_ylabel('Survival function, P(X>x)')\n",
    "\n",
    "axes[0].set_ylim([1/(1.1*len(subtree_descendants)), 1])\n",
    "axes[0].legend()\n",
    "\n",
    "x1, y1 = survival_func(subtree_depths)\n",
    "x2, y2 = survival_func(shuffled_depths)\n",
    "\n",
    "axes[1].plot(x1[y1>0], y1[y1>0], color='red', label='Data')\n",
    "axes[1].plot(x2[y2>0], y2[y2>0], color='black', label='Shuffled')\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].set_xlabel('Tree depth after migration, x')\n",
    "axes[1].set_ylim([1/(1.1*len(subtree_descendants)), 1])\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(r'Figures\\Supplementary\\Subtree_Stats.pdf', format='pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE S12: Frequency of migrant lineages in root vs non-root follicles\n",
    "\n",
    "freq_list_root = []\n",
    "freq_list_nonroot = []\n",
    "N_list_root = []\n",
    "N_list_nonroot = []\n",
    "lin_sizes = []\n",
    "\n",
    "for lineage in df_IGH_IF['lineage_id'].unique():\n",
    "    df_lin = df_IGH_IF[df_IGH_IF['lineage_id'] == lineage]\n",
    "    if df_lin['v_mutations'].nunique() <= 1 or df_lin['follicle'].nunique() <= 1: continue\n",
    "    lin_sizes.append(len(df_lin))\n",
    "\n",
    "    lin_id = int(float(lineage))\n",
    "    tree = Phylo.read(\"Data/Lineage_Seqs/Lineage_Trees/tree_lin_\" + str(lin_id) + \"_no_ef.newick\", \"newick\")\n",
    "\n",
    "    root_flag = False\n",
    "    for clade in tree.find_clades():\n",
    "        if clade.name and clade.name.startswith(\"ROOT\"):\n",
    "            tree.root_with_outgroup(clade)\n",
    "            if clade.name == \"ROOT__INFERRED\": tree.collapse(clade)\n",
    "            root_flag = True\n",
    "            break\n",
    "    if not root_flag: print(\"Error: No root found\")\n",
    "\n",
    "    label_tips(tree, df_IGH_IF, lineage, ignore_EF = True)\n",
    "    fill_internal_nodes(tree,lineage, df_IGH_IF, track_dominant = True)\n",
    "\n",
    "    root_foll = tree.root.metadata['foll']\n",
    "    max_N = 0\n",
    "    max_f = 0\n",
    "    max_N_name = None\n",
    "    max_f_name = None\n",
    "\n",
    "    for foll in df_lin['follicle'].unique():\n",
    "        N_foll = len(df_IGH_IF[df_IGH_IF['follicle'] == foll])\n",
    "        if foll == root_foll:\n",
    "            N_list_root.append(len(df_lin[df_lin['follicle'] == foll]))\n",
    "            freq_list_root.append(len(df_lin[df_lin['follicle'] == foll])/N_foll)\n",
    "        else:\n",
    "            if len(df_lin[df_lin['follicle'] == foll]) > max_N:\n",
    "                max_N = len(df_lin[df_lin['follicle'] == foll])\n",
    "                max_N_name = foll\n",
    "            if len(df_lin[df_lin['follicle'] == foll])/N_foll > max_f:\n",
    "                max_f = len(df_lin[df_lin['follicle'] == foll])/N_foll\n",
    "                max_f_name = foll\n",
    "\n",
    "    N_list_nonroot.append(len(df_lin[df_lin['follicle'] == max_N_name]))\n",
    "    freq_list_nonroot.append(len(df_lin[df_lin['follicle'] == max_f_name])/len(df_IGH_IF[df_IGH_IF['follicle'] == max_f_name]))\n",
    "\n",
    "freq_list_root = np.array(freq_list_root)\n",
    "freq_list_nonroot = np.array(freq_list_nonroot)\n",
    "N_list_root = np.array(N_list_root)\n",
    "N_list_nonroot = np.array(N_list_nonroot)\n",
    "lin_sizes = np.array(lin_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(freq_list_nonroot > freq_list_root)/len(freq_list_root),np.sum(N_list_nonroot > N_list_root)/len(N_list_nonroot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Left subplot: N_list_root vs N_list_nonroot\n",
    "axes[0].scatter(N_list_root, N_list_nonroot, color='black', alpha=0.5, s=lin_sizes)\n",
    "axes[0].set_xscale('log')\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].plot([1, 250], [1, 250], color='red', linestyle='--')\n",
    "axes[0].set_xlabel('Number UMIs in donor follicle')\n",
    "axes[0].set_ylabel('Number UMIs in max. recipient follicle')\n",
    "axes[0].set_xlim([0.9, 225])\n",
    "axes[0].set_ylim([0.9, 225])\n",
    "axes[0].set_aspect('equal', adjustable='box')\n",
    "\n",
    "# Right subplot: freq_list_root vs freq_list_nonroot\n",
    "axes[1].scatter(freq_list_root, freq_list_nonroot, color='black', alpha=0.5, s=lin_sizes)\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "axes[1].set_xlabel('Frequency donor follicle')\n",
    "axes[1].set_ylabel('Frequency in max. recipient follicle')\n",
    "axes[1].set_xlim([0.0005, 0.3])\n",
    "axes[1].set_ylim([0.0005, 0.3])\n",
    "axes[1].set_aspect('equal', adjustable='box')\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(r'Figures\\Supplementary/Lineage_Origin_Destination.pdf', format='pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
